<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Sentiment analysis with SVM and Binomial NB on Presidential Debate - ML journey</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/fontawesome.min.css" rel="stylesheet">
        <link href="../css/brands.min.css" rel="stylesheet">
        <link href="../css/solid.min.css" rel="stylesheet">
        <link href="../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">ML journey</a>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#sentiment-analysis-with-svm-and-binomial-nb-on-presidential-debate" class="nav-link">Sentiment analysis with SVM and Binomial NB on Presidential Debate</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#first-we-downsample-the-data-to-stratify-the-class" class="nav-link">First we downsample the data to stratify the class</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#next-we-clean-the-data" class="nav-link">Next we clean the data</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#next-we-do-vectorization-with-tfidf" class="nav-link">Next we do vectorization with tfidf</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#comparing-model" class="nav-link">Comparing model</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#most-sentiment-word" class="nav-link">Most "sentiment" word</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="sentiment-analysis-with-svm-and-binomial-nb-on-presidential-debate">Sentiment analysis with SVM and Binomial NB on Presidential Debate</h1>
<p>This exercise derived from Data Mining project in my college but i improvise with SVM. My team scraped and manually label the data before, so we just need to do some preprocess.</p>
<pre><code class="language-python">import pandas as pd
</code></pre>
<pre><code class="language-python">pd.set_option('display.max_colwidth', None)
df = pd.read_csv(&quot;dataset/president_debate.csv&quot;)
df = df.dropna()
df
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>full_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>Ganjar menyebut pernyataan itu disampaikan Jokowi saat debat Capres di tahun 2019 silam. Saat itu Ganjar merupakan salah satu tim kampanye Jokowi. TAG: Jokowi | Ganjar | anies final stage | prabowo | all in 02 | Ketua KPU | Australia | agak laen | pemilu 2024 | pemilu 2019 https://t.co/QuEav9i1Bw</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>@pikiranlugu @99propaganda @bengkeldodo @Ndons_Back @BANGSAygSUJUD @_NusantaraLand_ @florieliciouss @are_inismyname @Reskiichsan8 @P4P4B0W0_2024 @AditBandit234 @kurawa Sadar lah kamu Erik jangan nyebar in isu murahan seperti itu..saya juga nonton debat terahir V dan Pak ANIS CAPRES 01 tidak punya Niat ataupun bicara akan meruba BUMN menjadi KOPERASI..VISI MISI pak ANIS RB Jelas..</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>@WagimanDeep212_ Dri debat terakhir kemarin nih. Makin mantep dan yakin pilih ganjar mahfud. Gaspolll ykin m3nang</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>@Dy_NPR Gak perlu kami prihatin dg modelan begini. Sdh sepuh kesehatan entah. Untungnya debat terakhir P Anies berwelas asih dg tidak membuat beliau berkaca2 lagi. Kpn nabgis massal? Bnyk yg nungguin nih https://t.co/e5A9ihPqLP</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>@tempodotco Selalu suka sama pembawaannya pak Anies yang adem apalagi pas debat semalem beliau keliatan tenang dan sudah mempersiapkan diri banget yuk bisa AMIN 1 putaran aja https://t.co/5RtE6Zop33</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1063</th>
      <td>1.0</td>
      <td>Tetapi itikad kita baik saya kira 3 paslon semuanya ingin yang terbaik untuk rakyat Indonesia kata Prabowo dalam pernyataan penutupnya di sesi debat kelima Pilpres 2024 yang digelar di Jakarta Convention Center (JCC) Jakarta Minggu (4/2).</td>
    </tr>
    <tr>
      <th>1064</th>
      <td>1.0</td>
      <td>@kompascom @aniesbaswedan Pak Anies berhasil bikin debat semalam jadi punya nuansa berbeda keren parah!</td>
    </tr>
    <tr>
      <th>1066</th>
      <td>1.0</td>
      <td>@kompascom @aniesbaswedan Debat semalam semakin berkesan dengan pesona dan kata-kata positif dari Pak Anies!</td>
    </tr>
    <tr>
      <th>1067</th>
      <td>1.0</td>
      <td>@IDNTimes kalo melihat dari debat capres terakhir kemarin aku bakalan mantepin hatiku buat pilih Ganjar-Mahfud</td>
    </tr>
    <tr>
      <th>1068</th>
      <td>1.0</td>
      <td>@raffimulyaa Nah kalo menurut orang2 debat kemarin gak asik krn ga panas. Menurut gue pak Anies pake strategi yang bagus buat debat terakhir ini. Ada remnya dan mengedepankan apa yang bakal dilakuin sebagai calon presiden kedepan. Masalahnya kl ngegoreng kyk sblmnya dah kelar kewarasan kita</td>
    </tr>
  </tbody>
</table>
<p>1018 rows Ã— 2 columns</p>
</div>

<pre><code class="language-python">df['label'].value_counts()
</code></pre>
<pre><code>label
1.0    681
0.0    337
Name: count, dtype: int64
</code></pre>
<h2 id="first-we-downsample-the-data-to-stratify-the-class">First we downsample the data to stratify the class</h2>
<pre><code class="language-python">positive = df[df['label'] == 1].sample(337, random_state=0)
negative = df[df['label'] == 0]
df = pd.concat([positive, negative])
df.label.value_counts()
</code></pre>
<pre><code>label
1.0    337
0.0    337
Name: count, dtype: int64
</code></pre>
<pre><code class="language-python">from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk
import re
nltk.download('punkt_tab')
nltk.download('punkt')
nltk.download('stopwords')
</code></pre>
<pre><code>[nltk_data] Downloading package punkt_tab to /home/luqman/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt_tab.zip.
[nltk_data] Downloading package punkt to /home/luqman/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package stopwords to /home/luqman/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!





True
</code></pre>
<h2 id="next-we-clean-the-data">Next we clean the data</h2>
<p>Tweet has username, tag, and links, we will get rid of that. We also need to remove stopword because it not helping us to determine the sentiment so basically reduce the dimension of the model.</p>
<pre><code class="language-python">def preprocess(text):
    text = text.lower()
    ## hapus url
    text = re.sub(r'http\S+|www.\S+', '', text)
    ## hapus username dan hastag
    text = re.sub(r'@\w+', '', text)
    text = re.sub(r'#\w+', '', text)
    ## hapus non ascii
    text = text.encode('ascii', 'ignore').decode('utf-8')
    ## hapus angka dan tanda baca
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    ## hapus stop word
    tokens = word_tokenize(text)
    st = set(stopwords.words('indonesian'))
    tokens = [word for word in tokens if word not in st]
    return ' '.join(tokens)

df['full_text'] = df['full_text'].apply(preprocess)
</code></pre>
<pre><code class="language-python">from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df['full_text'], df['label'], stratify=df['label'], shuffle=True, random_state=0)
</code></pre>
<h2 id="next-we-do-vectorization-with-tfidf">Next we do vectorization with tfidf</h2>
<p>It similar to bag of word but instead of count we do tf*idf which term frequency(simplest: count of that word in that document) * inverse document frequency(how much document have that word accross all documents). When the word is rare the weight is higher, tfidf suit our need to measure different word on how important that word is, so we can decide positive or negative sentiment better.  </p>
<pre><code class="language-python">from sklearn.feature_extraction.text import TfidfVectorizer
tf = TfidfVectorizer()
X_train = tf.fit_transform(X_train)
X_test = tf.transform(X_test)
X_train.shape
</code></pre>
<pre><code>(763, 4023)
</code></pre>
<pre><code class="language-python">from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB, BernoulliNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
</code></pre>
<h2 id="comparing-model">Comparing model</h2>
<p>we compare linear SVM (draw decision line counting only closer/support data), naive bayes (use bayes theorem with assumption all word independent and based on binomial/bernoulli distribution), dan Logistic regression (similar to bernoulli NB but instead using bayes theorem we use gradient descent to model the mean)
- It looks like the sentiment is linearly separable and linear svm outperform for this random seed data
- BernoulliNB offer more precision with recall trade off
- Logistic regression easiest to interpret, we can select most positive/negative weight to see which word is mostly determine positve and negative sentiment.</p>
<h3 id="based-on-logistic-regression">based on logistic regression</h3>
<p>Top positive words:
- ganjar: 1.9254
- mahfud: 1.9136
- mohmahfudmd: 1.4525
- aniesbaswedan: 1.325</p>
<p>Top negative words:
- prabowo: -2.0228
- bansos: -1.9204
- apa: -1.4161
- jokowi: -1.1784</p>
<pre><code class="language-python">linsvm = SVC(kernel='linear')
linsvm.fit(X_train, y_train)
pred_linsvm = linsvm.predict(X_test)
print(classification_report(y_test, pred_linsvm), accuracy_score(y_test, pred_linsvm))
</code></pre>
<pre><code>              precision    recall  f1-score   support

         0.0       0.86      0.88      0.87        85
         1.0       0.88      0.86      0.87        84

    accuracy                           0.87       169
   macro avg       0.87      0.87      0.87       169
weighted avg       0.87      0.87      0.87       169
 0.8698224852071006
</code></pre>
<pre><code class="language-python">bnb = BernoulliNB()
bnb.fit(X_train, y_train)
pred_bnb = bnb.predict(X_test)
print(classification_report(y_test, pred_bnb), accuracy_score(y_test, pred_bnb))
</code></pre>
<pre><code>              precision    recall  f1-score   support

         0.0       0.91      0.68      0.78        85
         1.0       0.74      0.93      0.83        84

    accuracy                           0.80       169
   macro avg       0.82      0.81      0.80       169
weighted avg       0.83      0.80      0.80       169
 0.8047337278106509
</code></pre>
<pre><code class="language-python">mnb = MultinomialNB()
mnb.fit(X_train, y_train)
pred_mnb = mnb.predict(X_test)
print(classification_report(y_test, pred_mnb), accuracy_score(y_test, pred_mnb))
</code></pre>
<pre><code>              precision    recall  f1-score   support

         0.0       0.85      0.85      0.85        85
         1.0       0.85      0.85      0.85        84

    accuracy                           0.85       169
   macro avg       0.85      0.85      0.85       169
weighted avg       0.85      0.85      0.85       169
 0.8461538461538461
</code></pre>
<pre><code class="language-python">lr = LogisticRegression()
lr.fit(X_train, y_train)
pred_lr = lr.predict(X_test)
print(classification_report(y_test, pred_lr), accuracy_score(y_test, pred_lr))
</code></pre>
<pre><code>              precision    recall  f1-score   support

         0.0       0.83      0.65      0.73        84
         1.0       0.85      0.94      0.89       171

    accuracy                           0.84       255
   macro avg       0.84      0.80      0.81       255
weighted avg       0.84      0.84      0.84       255
 0.8431372549019608
</code></pre>
<h2 id="most-sentiment-word">Most "sentiment" word</h2>
<pre><code class="language-python">feature_names = tf.get_feature_names_out()
coefficients = lr.coef_[0]  # hanya 1 baris untuk binary classification

# Top kata positif dan negatif
top_pos = sorted(zip(coefficients, feature_names), reverse=True)[:10]
top_neg = sorted(zip(coefficients, feature_names))[:10]

print(&quot;Top positive words:&quot;)
for coef, word in top_pos:
    print(f&quot;{word}: {coef:.4f}&quot;)

print(&quot;\nTop negative words:&quot;)
for coef, word in top_neg:
    print(f&quot;{word}: {coef:.4f}&quot;)
</code></pre>
<pre><code>Top positive words:
ganjar: 1.9254
mahfud: 1.9136
mohmahfudmd: 1.4525
aniesbaswedan: 1.3253
co: 1.3187
pak: 1.3028
https: 1.3028
ganjarmahfud2024: 1.2753
ganjarpranowo: 1.2635
yang: 1.2433

Top negative words:
prabowo: -2.0228
bansos: -1.9204
apa: -1.4161
jokowi: -1.1784
aja: -1.1065
ga: -1.0893
covid: -1.0787
19: -1.0573
bermasalah: -1.0573
dikorupsi: -1.0573
</code></pre>
<pre><code class="language-python">
</code></pre></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js"></script>
        <script src="../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
