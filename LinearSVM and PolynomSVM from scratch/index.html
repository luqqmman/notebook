<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Linear and Polynom SVM from scratch - ML journey</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/fontawesome.min.css" rel="stylesheet">
        <link href="../css/brands.min.css" rel="stylesheet">
        <link href="../css/solid.min.css" rel="stylesheet">
        <link href="../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">ML journey</a>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#linear-and-polynom-svm-from-scratch" class="nav-link">Linear and Polynom SVM from scratch</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#we-use-the-iris-dataset" class="nav-link">We use the iris dataset</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="linear-and-polynom-svm-from-scratch">Linear and Polynom SVM from scratch</h1>
<p>We will create SVM using the loss function and do the gradient descend manually</p>
<pre><code class="language-python">import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
</code></pre>
<pre><code class="language-python">df = pd.read_csv(&quot;dataset/Iris.csv&quot;, index_col=&quot;Id&quot;)
</code></pre>
<h2 id="we-use-the-iris-dataset">We use the iris dataset</h2>
<p>But to make things simple we only classify is it iris setosa or not, because iris versicolor and iris virginica is'nt linearly separable</p>
<pre><code class="language-python">sns.pairplot(df, hue=&quot;Species&quot;)
plt.show()
</code></pre>
<p><img alt="png" src="../LinearSVM%20and%20PolynomSVM%20from%20scratch_files/LinearSVM%20and%20PolynomSVM%20from%20scratch_4_0.png" /></p>
<pre><code class="language-python">x = np.array(df.drop(columns=[&quot;Species&quot;, &quot;SepalLengthCm&quot;, &quot;SepalWidthCm&quot;]))
y = np.array([s == 'Iris-setosa' for s in df[&quot;Species&quot;]])
</code></pre>
<pre><code class="language-python">from sklearn.preprocessing import StandardScaler

X_train, X_test, Y_train, Y_test = train_test_split(x, y, stratify=y, random_state=7)
# scaler = StandardScaler()
# X_train = scaler.fit_transform(X_train)
</code></pre>
<pre><code class="language-python">def perceptron(lx, ly, maxiter=1000):
    theta = np.zeros(len(lx[0]), dtype=float)
    theta_0 = 0

    history = []
    for _ in range(maxiter):
        count = 0
        for x, y in zip(lx, ly):
            y = 1 if bool(y) else -1
            z = y * np.dot(theta, x) + theta_0
            if z &lt;= 0:
                theta += y * x
                theta_0 += y
                history.append(np.copy(theta))
                count += 1
        if count == 0:
            break
    return theta_0, theta
</code></pre>
<pre><code class="language-python">theta_0, theta = perceptron(X_train, Y_train)
</code></pre>
<pre><code class="language-python">count = 0
# X_test = scaler.transform(X_test)
for x, y in zip(X_test, Y_test):
    z = theta_0 + np.dot(x, theta)
    count += ((z &gt; 0) and y)
    count += ((z &lt; 0) and not y)
</code></pre>
<pre><code class="language-python">count/len(Y_test)
</code></pre>
<pre><code>0.5263157894736842
</code></pre>
<pre><code class="language-python">theta
</code></pre>
<pre><code>array([-0.1, -2.2])
</code></pre>
<pre><code class="language-python">theta_0
</code></pre>
<pre><code>5
</code></pre>
<pre><code class="language-python">
</code></pre>
<pre><code class="language-python">class LinearSVM:
    def __init__(self, lx, ly):
        self.theta = np.zeros(len(lx[0]), dtype=float)
        self.theta_0 = 0
        self.lmbd = 0.1
        self.lr = 0.001
        self.maxiter=1000
        self.lx = lx
        self.ly = ly

    def transform_data(self, func):
        self.lx = np.apply_along_axis(func, 1, self.lx)
        self.theta = np.zeros(len(self.lx[0]), dtype=float)

    def train(self):
        history = []
        for _ in range(self.maxiter):
            count = 0
            for x, y in zip(self.lx, self.ly):
                y = 1 if bool(y) else -1
                z = 1 - (y * (np.dot(self.theta, x) + self.theta_0))
                gradient_theta = self.dregterm_dtheta(x)
                gradient_theta_0 = 0
                if z &gt; 0:
                    gradient_theta += self.dlossterm_dtheta(x, y)
                    gradient_theta_0 += self.dlossterm_dtheta_0(y)
                    count += 1
                self.theta -= gradient_theta * self.lr
                self.theta_0 -= gradient_theta_0 * self.lr

                history.append(np.copy(self.theta))
            # if count == 0:
            #     break
        # print(history)
        return self.theta_0, self.theta

    def dregterm_dtheta(self, x):
        return self.lmbd * self.theta

    def dlossterm_dtheta(self, x, y):
        return -y*x

    def dlossterm_dtheta_0(self, y):
        return -y

    def predict(self, lx_test, ly_test):
        count = 0
        for x, y in zip(lx_test, ly_test):
            z = self.theta_0 + np.dot(x, self.theta)
            count += ((z &gt; 0) and y)
            count += ((z &lt; 0) and not y)
        return count / len(lx_test)

    def plot(self):
        # Plot data points
        plt.scatter(self.lxx[:, 0], self.lxx[:, 1], c=self.lyy, cmap=plt.cm.Paired, edgecolors='k', label='Data Points')

        # Plot decision boundary
        x1 = np.linspace(min(self.lxx[:, 0]), max(self.lxx[:, 0]), 100)
        x2 = -(self.theta[0] * x1 + self.theta_0) / self.theta[1]
        plt.plot(x1, x2, 'k-', label='Decision Boundary')

        # Plot margin boundaries
        margin = 1 / np.linalg.norm(self.theta)
        x2_upper = x2 + margin / np.linalg.norm(self.theta)
        x2_lower = x2 - margin / np.linalg.norm(self.theta)
        plt.plot(x1, x2_upper, 'k--', label='Margin Boundary', color=&quot;red&quot;)
        plt.plot(x1, x2_lower, 'k--', color=&quot;red&quot;)

        # Add labels and legend
        plt.xlabel('Feature 1')
        plt.ylabel('Feature 2')
        plt.title('Linear SVM Decision and Margin Boundaries')
        plt.legend()
        plt.show()

</code></pre>
<pre><code class="language-python">s = LinearSVM(X_train, Y_train)
</code></pre>
<pre><code class="language-python">s.train()
</code></pre>
<pre><code>(-0.8530000000000006, array([-0.83165633, -0.66812085]))
</code></pre>
<pre><code class="language-python">s.predict(X_test, Y_test)
</code></pre>
<pre><code>np.float64(1.0)
</code></pre>
<pre><code class="language-python">s.plot()
</code></pre>
<pre><code>/tmp/ipykernel_4050/4131259921.py:68: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string "k--" (-&gt; color='k'). The keyword argument will take precedence.
  plt.plot(x1, x2_upper, 'k--', label='Margin Boundary', color="red")
/tmp/ipykernel_4050/4131259921.py:69: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string "k--" (-&gt; color='k'). The keyword argument will take precedence.
  plt.plot(x1, x2_lower, 'k--', color="red")
</code></pre>
<p><img alt="png" src="../LinearSVM%20and%20PolynomSVM%20from%20scratch_files/LinearSVM%20and%20PolynomSVM%20from%20scratch_18_1.png" /></p>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt

class PolynomSVM:
    def __init__(self, lx, ly):
        self.copy_lx = lx
        self.lx = np.apply_along_axis(self.polynom, 1, lx)
        self.theta = np.zeros(len(self.lx[0]), dtype=float)
        self.theta_0 = 0
        self.lmbd = 0.9
        self.lr = 0.001
        self.maxiter = 1000
        self.ly = ly

    @staticmethod
    def polynom(arr):
        s = np.sqrt(2)
        return np.array([s * arr[0], s * arr[1], arr[0] ** 2, arr[1] ** 2, s * arr[0] * arr[1], 1])

    def train(self):
        for _ in range(self.maxiter):
            for x, y in zip(self.lx, self.ly):
                y = 1 if bool(y) else -1
                z = 1 - (y * (np.dot(self.theta, x) + self.theta_0))
                gradient_theta = self.lmbd * self.theta
                gradient_theta_0 = 0
                if z &gt; 0:
                    gradient_theta -= y * x
                    gradient_theta_0 -= y
                self.theta -= gradient_theta * self.lr
                self.theta_0 -= gradient_theta_0 * self.lr
        return self.theta_0, self.theta

    def predict(self, lx_test, ly_test):
        lx_test = np.apply_along_axis(self.polynom, 1, lx_test)
        predictions = np.dot(lx_test, self.theta) + self.theta_0
        correct_predictions = ((predictions &gt; 0) == ly_test).sum()
        print((predictions&gt;0).sum())
        print(len(lx_test))
        return correct_predictions / len(lx_test)

    def plot(self):
        x_min, x_max = self.copy_lx[:, 0].min() - 1, self.copy_lx[:, 0].max() + 1
        y_min, y_max = self.copy_lx[:, 1].min() - 1, self.copy_lx[:, 1].max() + 1
        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))

        grid = np.c_[xx.ravel(), yy.ravel()]
        grid_transformed = np.apply_along_axis(self.polynom, 1, grid)
        zz = np.dot(grid_transformed, self.theta) + self.theta_0
        zz = zz.reshape(xx.shape)

        plt.contourf(xx, yy, zz, levels=[-1, 0, 1], alpha=0.2, colors=[&quot;blue&quot;, &quot;black&quot;, &quot;red&quot;])
        plt.contour(xx, yy, zz, levels=[-1, 0, 1], colors=[&quot;blue&quot;, &quot;black&quot;, &quot;red&quot;], linestyles=[&quot;dashed&quot;, &quot;solid&quot;, &quot;dashed&quot;])

        plt.scatter(self.copy_lx[:, 0], self.copy_lx[:, 1], c=self.ly, cmap=plt.cm.Paired, edgecolors='k')
        plt.xlabel(&quot;Feature 1&quot;)
        plt.ylabel(&quot;Feature 2&quot;)
        plt.title(&quot;Polynomial SVM Decision Boundary&quot;)
        plt.show()
</code></pre>
<pre><code class="language-python">s = PolynomSVM(X_train, Y_train)
</code></pre>
<pre><code class="language-python">s.train()
</code></pre>
<pre><code>(-0.8980000000000007,
 array([-0.29973561, -0.27545061,  0.1579069 ,  0.10840018,  0.19147607,
        -0.00051781]))
</code></pre>
<pre><code class="language-python">s.plot()
</code></pre>
<p><img alt="png" src="../LinearSVM%20and%20PolynomSVM%20from%20scratch_files/LinearSVM%20and%20PolynomSVM%20from%20scratch_22_0.png" /></p>
<pre><code class="language-python">s.predict(X_test, Y_test)
</code></pre>
<pre><code>13
38





np.float64(1.0)
</code></pre></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js"></script>
        <script src="../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
